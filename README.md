# Qwen3-VL Finetuning on VietTravelVQA

Fine-tune **Qwen3-VL-4B-Instruct** trÃªn bá»™ dá»¯ liá»‡u **VietTravelVQA** sá»­ dá»¥ng **Unsloth** vá»›i **4-bit quantization**.

ğŸ“š **Docs:** https://unsloth.ai/docs/models/qwen3-vl-how-to-run-and-fine-tune

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

- **GPU:** NVIDIA GPU vá»›i â‰¥8GB VRAM (4B model), â‰¥16GB (8B model)
- **Python:** 3.10+
- **CUDA:** 11.8+ hoáº·c 12.x

## ğŸš€ CÃ i Ä‘áº·t

```bash
# 1. Táº¡o virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac

# 2. CÃ i Ä‘áº·t Unsloth
pip install unsloth

# 3. CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# 4. (Optional) Flash Attention cho tá»‘c Ä‘á»™ tá»‘t hÆ¡n
pip install flash-attn --no-build-isolation
```

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c

```
VQA/
â”œâ”€â”€ VietTravelVQA/              # Dataset
â”‚   â”œâ”€â”€ images/                 # 1406 images
â”‚   â”œâ”€â”€ viettravelvqa_train.json  # 1124 images, 5620 QA pairs
â”‚   â””â”€â”€ viettravelvqa_test.json   # 282 images, 1410 QA pairs
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ training_config.yaml    # Training configuration
â”œâ”€â”€ finetune_qwen3vl.py         # Main training script
â”œâ”€â”€ inference.py                # Inference script
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md
```

## ğŸ¯ Training

### Quick Test (50 samples)

```bash
python finetune_qwen3vl.py --max_samples 50 --max_steps 30
```

### Full Training

```bash
python finetune_qwen3vl.py
```

### Custom Training

```bash
python finetune_qwen3vl.py \
    --model_name unsloth/Qwen3-VL-4B-Instruct-unsloth-bnb-4bit \
    --epochs 3 \
    --batch_size 2 \
    --grad_accum 4 \
    --lr 2e-4 \
    --lora_r 16 \
    --output_dir ./outputs/my_experiment
```

### Training Arguments

| Argument | Default | Description |
|----------|---------|-------------|
| `--model_name` | `unsloth/Qwen3-VL-4B-Instruct-unsloth-bnb-4bit` | Model trÃªn HuggingFace |
| `--epochs` | 3 | Sá»‘ epochs |
| `--batch_size` | 2 | Batch size per GPU |
| `--grad_accum` | 4 | Gradient accumulation |
| `--lr` | 2e-4 | Learning rate |
| `--lora_r` | 16 | LoRA rank |
| `--lora_alpha` | 16 | LoRA alpha |
| `--max_steps` | -1 | Max steps (-1 = use epochs) |
| `--max_samples` | None | Limit samples (for testing) |
| `--save_gguf` | False | Export to GGUF format |

## ğŸ” Inference

### Single Image

```bash
python inference.py \
    --model_path outputs/qwen3vl-viettravelvqa/lora_model \
    --image VietTravelVQA/images/VN_000744.jpg \
    --question "ÄÃ¢y lÃ  cÃ´ng trÃ¬nh kiáº¿n trÃºc gÃ¬?"
```

### With Streaming Output

```bash
python inference.py \
    --model_path outputs/qwen3vl-viettravelvqa/lora_model \
    --image VietTravelVQA/images/VN_000744.jpg \
    --question "MÃ´ táº£ chi tiáº¿t hÃ¬nh áº£nh nÃ y" \
    --stream
```

### Batch Evaluation

```bash
python inference.py \
    --model_path outputs/qwen3vl-viettravelvqa/lora_model \
    --mode batch \
    --test_file VietTravelVQA/viettravelvqa_test.json \
    --max_samples 100 \
    --output predictions.json
```

## ğŸ§  Model Architecture

### Unsloth Pre-quantized Models

| Model | VRAM | HuggingFace |
|-------|------|-------------|
| 2B | ~6GB | `unsloth/Qwen3-VL-2B-Instruct-unsloth-bnb-4bit` |
| **4B** | ~8GB | `unsloth/Qwen3-VL-4B-Instruct-unsloth-bnb-4bit` |
| 8B | ~12GB | `unsloth/Qwen3-VL-8B-Instruct-unsloth-bnb-4bit` |
| 32B | ~24GB | `unsloth/Qwen3-VL-32B-Instruct-unsloth-bnb-4bit` |

### LoRA Configuration

```python
model = FastVisionModel.get_peft_model(
    model,
    finetune_vision_layers=True,     # Vision encoder
    finetune_language_layers=True,   # LLM layers
    finetune_attention_modules=True, # Q, K, V, O
    finetune_mlp_modules=True,       # gate, up, down
    r=16,
    lora_alpha=16,
)
```

## ğŸ“Š Dataset Info

**VietTravelVQA** - VQA dataset vá» du lá»‹ch Viá»‡t Nam:

| Split | Images | QA Pairs | QA/Image |
|-------|--------|----------|----------|
| Train | 1,124 | 5,620 | 5 |
| Test | 282 | 1,410 | 5 |

**Difficulty Levels:**
1. **Very Easy** - Thuá»™c tÃ­nh Ä‘Æ¡n giáº£n (mÃ u sáº¯c, sá»‘ lÆ°á»£ng)
2. **Easy** - Suy luáº­n cÆ¡ báº£n (Ä‘á»c biá»ƒn, vá»‹ trÃ­)
3. **Medium** - Nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng (tÃªn Ä‘á»‹a danh)
4. **Hard** - Suy luáº­n ngá»¯ cáº£nh (vÄƒn hÃ³a, lá»‹ch sá»­)
5. **Very Hard** - Suy luáº­n Ä‘a bÆ°á»›c vá»›i kiáº¿n thá»©c ngoÃ i

## ğŸ’¾ Export Models

### Save to GGUF (for llama.cpp)

```bash
python finetune_qwen3vl.py --save_gguf --gguf_quant q4_k_m
```

### Load and use GGUF

```bash
# Using llama.cpp
./llama-mtmd-cli \
    -hf unsloth/Qwen3-VL-4B-Instruct-GGUF:UD-Q4_K_XL \
    --n-gpu-layers 99 \
    --jinja \
    --top-p 0.8 --top-k 20 --temp 0.7
```

## ğŸ“ Recommended Settings

### Instruct Model
- Temperature: 0.7
- Top-P: 0.8
- Top-K: 20
- Presence Penalty: 1.5

### Thinking Model
- Temperature: 1.0
- Top-P: 0.95
- Top-K: 20
- Presence Penalty: 0.0

## ğŸ”— References

- [Unsloth Qwen3-VL Guide](https://unsloth.ai/docs/models/qwen3-vl-how-to-run-and-fine-tune)
- [Colab Notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_VL_(8B)-Vision.ipynb)
- [VietTravelVQA Dataset](./VietTravelVQA/README.md)

## ğŸ“œ License

- **Dataset:** CC BY 4.0
- **Images:** Creative Commons (Wikimedia Commons)
- **Code:** MIT License
