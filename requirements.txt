# Qwen3-VL Finetuning with Unsloth
# Based on: https://unsloth.ai/docs/models/qwen3-vl-how-to-run-and-fine-tune
# GPU Required: NVIDIA GPU with 8GB+ VRAM (4B model)

# =============================================================================
# Core - Unsloth (install first)
# =============================================================================
unsloth

# =============================================================================
# Transformers (specific version for compatibility)
# =============================================================================
transformers>=4.57.0

# =============================================================================
# Training
# =============================================================================
trl>=0.22.0
peft>=0.10.0
accelerate>=0.27.0

# =============================================================================
# 4-bit Quantization
# =============================================================================
bitsandbytes>=0.42.0

# =============================================================================
# Image Processing
# =============================================================================
Pillow>=10.0.0

# =============================================================================
# Tokenization
# =============================================================================
sentencepiece>=0.1.99
protobuf>=4.0.0

# =============================================================================
# Data & Utils
# =============================================================================
datasets>=4.3.0
huggingface_hub>=0.34.0
hf_transfer

# =============================================================================
# Optional: Wandb for logging
# =============================================================================
# wandb>=0.16.0

# =============================================================================
# Utils
# =============================================================================
tqdm>=4.66.0
numpy>=1.24.0
pyyaml>=6.0

# =============================================================================
# Optional: Flash Attention (for faster training)
# pip install flash-attn --no-build-isolation
# =============================================================================
